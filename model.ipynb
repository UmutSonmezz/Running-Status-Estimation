{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d6a95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1596f529",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML için\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Görsel ayarlar\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd10d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50009a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b04452",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le  # hangi sınıf hangi label'a denk geliyor, bunu kaydeder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoders[\"Gender\"].classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae123394",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoders[\"Attrition\"].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7339ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_counts = df['Attrition'].value_counts()\n",
    "print(attrition_counts)\n",
    "print(\"\\nOranlar:\")\n",
    "print(attrition_counts / len(df))\n",
    "\n",
    "# Görselleştirme\n",
    "sns.countplot(data=df, x='Attrition')\n",
    "plt.title('Attrition Sınıf Dağılımı')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='Attrition')\n",
    "plt.title(\"Çalışanların İşten Ayrılma Durumu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd44f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Gender', hue='Attrition', data=df)\n",
    "plt.title(\"Cinsiyete Göre İşten Ayrılma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsAtCompany'].hist(bins=20)\n",
    "plt.title(\"Şirkette Geçirilen Yılların Dağılımı\")\n",
    "plt.xlabel(\"Yıl\")\n",
    "plt.ylabel(\"Çalışan Sayısı\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c092b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='Attrition', y='Age', data=df)\n",
    "plt.title(\"Yaşa Göre İşten Ayrılma Yoğunluğu\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(df.corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Değişkenler Arası Korelasyon\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6afc2",
   "metadata": {},
   "source": [
    "TEST - TRAİN DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Attrition\" , axis = 1)\n",
    "y= df[\"Attrition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a79e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad941546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train , y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"Final shapes:\")\n",
    "print(f\"Train: {X_resampled.shape}\")\n",
    "print(f\"Val: {X_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sınıf dağılımlarını karşılaştır\n",
    "print(\"SMOTE ETKİSİ:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"ÖNCE (Orijinal):\")\n",
    "original_counts = pd.Series(y_train).value_counts()\n",
    "print(f\"Kalmış (0): {original_counts[0]} kişi\")\n",
    "print(f\"Ayrılmış (1): {original_counts[1]} kişi\")\n",
    "print(f\"Oran: {original_counts[1]/original_counts[0]:.2f}\")\n",
    "\n",
    "print(\"\\nSONRA (SMOTE):\")\n",
    "smote_counts = pd.Series(y_resampled).value_counts()\n",
    "print(f\"Kalmış (0): {smote_counts[0]} kişi\")\n",
    "print(f\"Ayrılmış (1): {smote_counts[1]} kişi\") \n",
    "print(f\"Oran: {smote_counts[1]/smote_counts[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ab519",
   "metadata": {},
   "source": [
    "MODEL TRAİN (XGBOOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(random_state = 42, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0150e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':[100, 200, 300], #ağaç sayısı\n",
    "    'max_depth':[3, 5, 7], #ağaç derinliği\n",
    "    'learning_rate': [0.01, 0.1, 0.2],#öğrenme oranı\n",
    "    'subsample':[0.8, 0.9, 1.0], #alt örnekleme oranı\n",
    "    'colsample_bytree':[0.8, 0.9, 1.0] #özellik alt örnekleme oranı \n",
    "}\n",
    "\n",
    "print(f\"Toplam test edilecek kombinasyon sayısı: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['learning_rate']) * len(param_grid['subsample']) * len(param_grid['colsample_bytree'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='f1',  # En iyi modeli F1 skoruna göre seç\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"\\nModel eğitimi başlıyor...\")\n",
    "grid_search.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEN İYİ PARAMETRELER:\")\n",
    "print(\"-\" * 30)\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "print(f\"\\nEn iyi CV skoru (ROC-AUC): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 6. En iyi modeli al\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 7. Validation seti ile değerlendir\n",
    "print(\"\\nVALIDATION SETİ DEĞERLENDİRMESİ:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_roc_auc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "val_accuracy = best_model.score(X_val, y_val)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# 8. Detaylı classification report\n",
    "print(\"\\nDetaylı Performans Raporu:\")\n",
    "print(classification_report(y_val, y_val_pred, \n",
    "                          target_names=['Kalmış', 'Ayrılmış']))\n",
    "\n",
    "# 9. Confusion Matrix görselleştirme\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Kalmış', 'Ayrılmış'],\n",
    "            yticklabels=['Kalmış', 'Ayrılmış'])\n",
    "plt.title('Validation Set - Confusion Matrix')\n",
    "plt.ylabel('Gerçek')\n",
    "plt.xlabel('Tahmin')\n",
    "plt.show()\n",
    "\n",
    "# 10. Feature Importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "feature_names = X_resampled.columns\n",
    "\n",
    "# En önemli 15 özellik\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=importance_df, y='feature', x='importance')\n",
    "plt.title('En Önemli 15 Özellik')\n",
    "plt.xlabel('Önem Skoru')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEn Önemli 10 Özellik:\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# 11. Test seti ile final değerlendirme\n",
    "print(\"\\nTEST SETİ (FINAL) DEĞERLENDİRMESİ:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nFinal Test Raporu:\")\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['Kalmış', 'Ayrılmış']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5febe57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name: str, model_object, metric: str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): what you want the model to be called in the output table\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): precision, recall, f1, or accuracy \n",
    "     \n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "    \n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                  'recall': 'mean_test_recall',\n",
    "                  'f1': 'mean_test_f1',\n",
    "                  'accuracy': 'mean_test_accuracy',\n",
    "                  'roc_auc': 'mean_test_roc_auc'\n",
    "                  }\n",
    "    \n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "    \n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "    \n",
    "    # Extract all scores from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "    \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                         'precision': [precision],\n",
    "                         'recall': [recall],\n",
    "                         'F1': [f1],\n",
    "                         'accuracy': [accuracy],\n",
    "                         'roc_auc': [roc_auc]\n",
    "                         })\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f7566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name: str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): Your choice: how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy]\n",
    "                        })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "163ea681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KARŞILAŞTIRMALI SONUÇLAR:\n",
      "==================================================\n",
      "Cross-Validation Sonuçları:\n",
      "                  model  precision  recall      F1  accuracy  roc_auc\n",
      "0  XGBoost + SMOTE (CV)     0.9105  0.8875  0.8837     0.899   0.9721\n",
      "\n",
      "Test Seti Sonuçları:\n",
      "     model  precision  recall    F1  accuracy\n",
      "0  XGBoost     0.4359  0.2787  0.34    0.8503\n",
      "\n",
      "TÜM SONUÇLAR:\n",
      "                  model  precision  recall      F1  accuracy  roc_auc\n",
      "0  XGBoost + SMOTE (CV)     0.9105  0.8875  0.8837    0.8990   0.9721\n",
      "1               XGBoost     0.4359  0.2787  0.3400    0.8503      NaN\n",
      "\n",
      "==================================================\n",
      "MODEL PERFORMANS ÖZETİ\n",
      "==================================================\n",
      "En iyi CV ROC-AUC: 0.8902\n",
      "Validation ROC-AUC: 0.8115\n",
      "Test ROC-AUC: 0.7943\n",
      "Validation Accuracy: 0.8605\n",
      "Test Accuracy: 0.8503\n",
      "\n",
      "⚠️  Uyarı: Model overfitting yapıyor olabilir!\n"
     ]
    }
   ],
   "source": [
    "cv_results = make_results('XGBoost + SMOTE (CV)', grid_search, 'roc_auc')\n",
    "\n",
    "# Test seti sonuçları\n",
    "test_results = get_test_scores('XGBoost', y_test_pred, y_test)\n",
    "\n",
    "print(\"\\nKARŞILAŞTIRMALI SONUÇLAR:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Cross-Validation Sonuçları:\")\n",
    "print(cv_results.round(4))\n",
    "print(\"\\nTest Seti Sonuçları:\")\n",
    "print(test_results.round(4))\n",
    "\n",
    "# İki tabloyu birleştir\n",
    "comparison_table = pd.concat([cv_results, test_results], ignore_index=True)\n",
    "print(\"\\nTÜM SONUÇLAR:\")\n",
    "print(comparison_table.round(4))\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANS ÖZETİ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"En iyi CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Validation ROC-AUC: {val_roc_auc:.4f}\")\n",
    "print(f\"Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Overfitting kontrolü\n",
    "if abs(grid_search.best_score_ - test_roc_auc) > 0.05:\n",
    "    print(\"\\n⚠️  Uyarı: Model overfitting yapıyor olabilir!\")\n",
    "else:\n",
    "    print(\"\\n✅ Model performansı tutarlı görünüyor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her CV fold'unda SMOTE'u ayrı ayrı uygula\n",
    "# Validation kısmına SMOTE uygulama\n",
    "# Böylece CV skoru daha gerçekçi olur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aday",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
